#!/usr/bin/env python3
"""Configure LLM provider settings for optimal performance."""

import os
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def configure_single_provider():
    """Configure single provider mode for optimal performance."""

    # Test results from our API testing
    provider_performance = {
        'groq': {'speed': 0.69, 'tokens': 100000, 'cost': 'free', 'priority': 1},
        'cohere': {'speed': 1.53, 'tokens': 1000, 'cost': 'paid', 'priority': 2},
        'ai21': {'speed': 1.39, 'tokens': 10000, 'cost': 'paid', 'priority': 3},
        'openai': {'speed': 1.93, 'tokens': 10000, 'cost': 'paid', 'priority': 4},
        'huggingface': {'speed': 1.77, 'tokens': 1000, 'cost': 'free', 'priority': 5},
        'ollama': {'speed': 5.38, 'tokens': 'unlimited', 'cost': 'free', 'priority': 6}
    }

    # Choose Groq as primary (fastest cloud provider with good limits)
    primary_provider = 'groq'

    print("CONFIGURING LLM PROVIDER SETTINGS")
    print("=" * 50)
    print(f"Selected Primary Provider: {primary_provider}")
    print(f"Performance: {provider_performance[primary_provider]['speed']}s response time")
    print(f"Token Limit: {provider_performance[primary_provider]['tokens']} per day")
    print(f"Cost: {provider_performance[primary_provider]['cost']}")
    print()

    # Update environment variables
    env_updates = {
        'SINGLE_PROVIDER': 'true',
        'PRIMARY_PROVIDER': primary_provider,
        'LLM_SELECTION_STRATEGY': 'single',
        'GROQ_API_KEY': 'GROQ_API_KEY_REDACTED',
        'GOOGLE_API_KEY': 'AIzaSyCEYoOsbt-FXzyV3Kh9i_fwmhvF3EsZSME',
        'COHERE_API_KEY': 'xXWGFBOCljq4vp5YNKJz7XTHAcPCv3e7lPDNsFHj',
        'OPENAI_API_KEY': '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',
        'AI21_API_KEY': 'e7616a6d-78bd-47dc-b076-539bacd710d9',
        'HUGGINGFACE_API_KEY': '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'
    }

    # Check if .env file exists
    env_file = Path('.env')
    if not env_file.exists():
        print("Creating .env file...")
        env_file.touch()

    # Read existing .env content
    existing_content = {}
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                line = line.strip()
                if '=' in line and not line.startswith('#'):
                    key, value = line.split('=', 1)
                    existing_content[key] = value

    # Update with new values
    existing_content.update(env_updates)

    # Write back to .env file
    with open(env_file, 'w') as f:
        f.write("# LLM Provider Configuration - Optimized for Performance\n")
        f.write("# Generated by configure_llm_provider.py\n\n")

        for key, value in sorted(existing_content.items()):
            if key in env_updates:
                f.write(f"{key}={value}\n")
            else:
                f.write(f"{key}={value}\n")

    print("Configuration updated in .env file")
    print()
    print("PERFORMANCE OPTIMIZATIONS:")
    print("- Single provider mode reduces API call distribution")
    print("- Groq selected for fastest response times (0.69s avg)")
    print("- 100K daily token limit maximizes throughput")
    print("- Automatic fallback if primary provider fails")
    print()
    print("To test the configuration:")
    print("python scripts/test_api_keys.py")
    print()
    print("To use in your application:")
    print("from genai_module.core.llm_provider_manager import LLMProviderManager")
    print("manager = LLMProviderManager()")
    print("response = manager.call_llm('system prompt', 'user message')")

if __name__ == "__main__":
    configure_single_provider()
